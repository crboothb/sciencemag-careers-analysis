{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create features from the raw text so we can train the machine learning models. The steps followed are:\n",
    "\n",
    "1. **Text Cleaning and Preparation**: cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization. \n",
    "2. **Label coding**: creation of a dictionary to map each category to a code.\n",
    "3. **Train-test split**: to test the models on unseen data.\n",
    "4. **Text representation**: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_func as imp\n",
    "import classifier_help as cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we'll load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"pickles/hand_coded_ALL.pickle\"\n",
    "# full_filename = \"../data/by_article_fulltext_112919-2.jl\" # OLD VERSION\n",
    "full_filename = \"../data/by_article_fulltext_020920.jl\"\n",
    "\n",
    "\n",
    "with open(path_df, 'rb') as data:\n",
    "    coded_df = pickle.load(data)\n",
    "\n",
    "df_full = imp.init_df(full_filename, \"full\", \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>first</th>\n      <th>second</th>\n      <th>wc</th>\n      <th>first_f</th>\n      <th>second_f</th>\n      <th>input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>730</td>\n      <td>54</td>\n      <td>0</td>\n      <td>850</td>\n      <td>0.063529</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4200</td>\n      <td>10</td>\n      <td>0</td>\n      <td>790</td>\n      <td>0.012658</td>\n      <td>0.000000</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4453</td>\n      <td>76</td>\n      <td>1</td>\n      <td>1088</td>\n      <td>0.069853</td>\n      <td>0.000919</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>286</td>\n      <td>3</td>\n      <td>64</td>\n      <td>1229</td>\n      <td>0.002441</td>\n      <td>0.052075</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1034</td>\n      <td>6</td>\n      <td>29</td>\n      <td>1322</td>\n      <td>0.004539</td>\n      <td>0.021936</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     id  first  second    wc   first_f  second_f  input\n0   730     54       0   850  0.063529  0.000000      1\n1  4200     10       0   790  0.012658  0.000000      3\n2  4453     76       1  1088  0.069853  0.000919      1\n3   286      3      64  1229  0.002441  0.052075      2\n4  1034      6      29  1322  0.004539  0.021936      3"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to cut the df down to only the ones that have been categorized and add the categories project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "197\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_x</th>\n      <th>first</th>\n      <th>second</th>\n      <th>wc</th>\n      <th>first_f</th>\n      <th>second_f</th>\n      <th>input</th>\n      <th>id_y</th>\n      <th>headline</th>\n      <th>tags</th>\n      <th>...</th>\n      <th>date</th>\n      <th>time</th>\n      <th>text</th>\n      <th>bio</th>\n      <th>date_seq</th>\n      <th>month_seq</th>\n      <th>year</th>\n      <th>n_posts_author</th>\n      <th>column1</th>\n      <th>column2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>730</td>\n      <td>54</td>\n      <td>0</td>\n      <td>850</td>\n      <td>0.063529</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>6055</td>\n      <td>diary of a british scientist, part 2: brushing...</td>\n      <td>[job market, europe]</td>\n      <td>...</td>\n      <td>1999-06-04</td>\n      <td>8:00 am</td>\n      <td>by           so after deciding that i wanted...</td>\n      <td>[]</td>\n      <td>977</td>\n      <td>42</td>\n      <td>1999</td>\n      <td>7</td>\n      <td>no</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4200</td>\n      <td>10</td>\n      <td>0</td>\n      <td>790</td>\n      <td>0.012658</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>3389</td>\n      <td>alyson reed takes the helm at npa</td>\n      <td>[issues and perspectives, advice, postdoc, ame...</td>\n      <td>...</td>\n      <td>2003-09-19</td>\n      <td>4:00 am</td>\n      <td>by     n 4 september, a new force joined the...</td>\n      <td>[xenia morin, ph.d., is a keck postdoctoral te...</td>\n      <td>2545</td>\n      <td>93</td>\n      <td>2003</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4453</td>\n      <td>76</td>\n      <td>1</td>\n      <td>1088</td>\n      <td>0.069853</td>\n      <td>0.000919</td>\n      <td>1</td>\n      <td>3612</td>\n      <td>unveiling the blindness</td>\n      <td>[workplace diversity, myscinet, undergraduate,...</td>\n      <td>...</td>\n      <td>2004-02-20</td>\n      <td>0:00 am</td>\n      <td>by      n a daily basis, i strive to be the ...</td>\n      <td>[]</td>\n      <td>2699</td>\n      <td>98</td>\n      <td>2004</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>286</td>\n      <td>3</td>\n      <td>64</td>\n      <td>1229</td>\n      <td>0.002441</td>\n      <td>0.052075</td>\n      <td>2</td>\n      <td>87</td>\n      <td>talk yourself right into a job</td>\n      <td>[tooling up, column, non-disciplinary]</td>\n      <td>...</td>\n      <td>2017-04-12</td>\n      <td>2:30 pm</td>\n      <td>by  i’m sure you’ve heard the expression use...</td>\n      <td>[]</td>\n      <td>7499</td>\n      <td>256</td>\n      <td>2017</td>\n      <td>247</td>\n      <td>no</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1034</td>\n      <td>6</td>\n      <td>29</td>\n      <td>1322</td>\n      <td>0.004539</td>\n      <td>0.021936</td>\n      <td>3</td>\n      <td>4704</td>\n      <td>loan-repayment for biomedical researchers</td>\n      <td>[advice, americas]</td>\n      <td>...</td>\n      <td>2001-12-14</td>\n      <td>0:00 am</td>\n      <td>by                            whatever happe...</td>\n      <td>[due to the high volume of questions received,...</td>\n      <td>1901</td>\n      <td>72</td>\n      <td>2001</td>\n      <td>84</td>\n      <td>no</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>",
      "text/plain": "   id_x  first  second    wc   first_f  second_f  input  id_y  \\\n0   730     54       0   850  0.063529  0.000000      1  6055   \n1  4200     10       0   790  0.012658  0.000000      3  3389   \n2  4453     76       1  1088  0.069853  0.000919      1  3612   \n3   286      3      64  1229  0.002441  0.052075      2    87   \n4  1034      6      29  1322  0.004539  0.021936      3  4704   \n\n                                            headline  \\\n0  diary of a british scientist, part 2: brushing...   \n1                  alyson reed takes the helm at npa   \n2                            unveiling the blindness   \n3                     talk yourself right into a job   \n4          loan-repayment for biomedical researchers   \n\n                                                tags  ...       date     time  \\\n0                               [job market, europe]  ... 1999-06-04  8:00 am   \n1  [issues and perspectives, advice, postdoc, ame...  ... 2003-09-19  4:00 am   \n2  [workplace diversity, myscinet, undergraduate,...  ... 2004-02-20  0:00 am   \n3             [tooling up, column, non-disciplinary]  ... 2017-04-12  2:30 pm   \n4                                 [advice, americas]  ... 2001-12-14  0:00 am   \n\n                                                text  \\\n0    by           so after deciding that i wanted...   \n1    by     n 4 september, a new force joined the...   \n2    by      n a daily basis, i strive to be the ...   \n3    by  i’m sure you’ve heard the expression use...   \n4    by                            whatever happe...   \n\n                                                 bio date_seq  month_seq  \\\n0                                                 []      977         42   \n1  [xenia morin, ph.d., is a keck postdoctoral te...     2545         93   \n2                                                 []     2699         98   \n3                                                 []     7499        256   \n4  [due to the high volume of questions received,...     1901         72   \n\n   year  n_posts_author  column1 column2  \n0  1999               7       no     yes  \n1  2003               1       no      no  \n2  2004               1       no      no  \n3  2017             247       no     yes  \n4  2001              84       no     yes  \n\n[5 rows x 21 columns]"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = coded_df.merge(right=df_full, how=\"left\", left_on=\"id\", right_index=True)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize one sample news content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3\n  by          dward ruthazer (pictured left) is a mapmaker of sorts, but the maps he makes are not of places in the world. ruthazer studies brain development, charting intricate neurocircuitries in the hope of advancing treatments for injuries of the central nervous system and therapies for developmental disorders. like the neural connections he maps, ruthazer's path has twisted and turned from china to japan and across north america, as he has investigated the mechanisms that shape the wiring of the human brain. for this young neuroscientist, working overseas in different cultures and acquiring new personal and professional skills provided a sense of independence and confidence as a researcher, qualities that he tries to instill in the students and trainees working in his laboratory.       less than a year after finishing his second postdoc at cold spring harbor laboratory in new york, ruthazer is settling in as assistant professor at mcgill university's montreal neurological institute (mni) in montreal, quebec. in his laboratory, ruthazer and his staff are asking fundamental questions about how the brain's neurocircuitry—the network of connections between neurons—develops.  using digital imagery and gene-transfer methods, he and his team observe labeled neurons in living tadpoles. the animals are subjected to sensory stimuli as the team analyzes alterations in neuronal connectivity. in one project, they place tadpoles in chambers with flashing lights and examine the changes in connectivity in the retinal ganglion cells in response to these visual stimulations. the results in tadpoles, says ruthazer, are of more than academic interest. \"we're not far removed from other vertebrate species, so what we learn from frogs is absolutely relevant to human development.\"   ruthazer believes that investigating animal neurocircuit development will eventually lead to a better understanding of diseases, including schizophrenia and autism, where abnormal neurological wiring is thought to occur early in life. the developing post-natal brain, ruthazer explains, forms and refines synaptic connections in response to a set of inputs from the environment, a process that becomes less robust with age. ruthazer hopes his research on rewiring may eventually bring hope to adults suffering from accidental brain injuries, and offer the possibility of early diagnosis and treatment of autism and schizophrenia. \"if we can re-introduce structural elasticity in adults, then the opportunity to recover from strokes, for example, is enormous.\"       as an undergraduate at princeton university, ruthazer exercised his own developing brain to fulfill longstanding interests in the life sciences and languages, graduating with a major in biology and a certificate in east asian studies. during this period he began to wonder how the human brain interprets environmental stimuli. while learning french and chinese, he became fascinated how sensory experiences, like language acquisition, are processed neurologically. \"i remember starting out with a simple interest in languages and language acquisition as a hobby,\" explains ruthazer. \"now it's taken me to looking at how the brain is hardwired, and understanding how the influence of environment can alter this wiring structure.\"   in his senior year at princeton in 1988, he completed his first neuroscience project, on songbird auditory systems. it was then that ruthazer decided that graduate school was his next step. but before he could commit to his research career, he says, he felt like he needed to practice his language skills, so he packed his bags and traveled to the southern tip of manchuria, china, to teach english for a year at a university. it was, he says, an amazing learning experience; being immersed in a culture and language so different from his own provided many new environmental stimuli.  back in the u.s. a year later, ruthazer commenced his neuroscience training, studying the plasticity of neural systems for his ph.d. at university of california at san francisco. in 1996, after he had completed his doctorate, he had an opportunity to do a postdoc in japan--his wife's homeland--on a joint national science foundation/japan society for the promotion of science  .  \"it was a good opportunity for us to live close to my wife's family and learn the culture,\" he explains. \"but on top of that, i knew that i wanted to learn about imaging work, and there was this lab at osaka university that had a known researcher in the field who was willing to take me on.\" under the supervision of nobuhiko yamamoto, he was able to observe the formation of synaptic connections using slices of functioning cortical tissues.       ruthazer feels that his 2-year postdoc in japan helped him become more independent. despite a lab environment that he calls \"extremely supportive,\" ruthazer found that he was unable to lean heavily on a culture that seemed foreign. \"when you leave your familiar support structure and you're an outsider, you have to find your niche by yourself.\" he may have found similar opportunities back in the united states, he observes, but going to japan also gave him the opportunity to learn state-of-the-art imaging techniques and to set up a valuable collaboration in a foreign country, while also developing a greater sense of independence.   ruthazer returned stateside in 1999 and took up a postdoc in holly cline's lab at cold spring harbor. cline, ruthazer recalls, entrusted him with some special opportunities. he was able to pursue novel experimental approaches on his own initiative, for instance, and to give talks on her behalf at meetings she was unable to attend. these opportunities further developed his sense of independence and gave him a better grasp of the direction his field was going in. ruthazer recommends that other scientific trainees pursue similar opportunities. \"when you choose a postdoctoral advisor one of the things that you should look for is that kind of generosity, the willingness to share,\" he says.       ruthazer's growing independence and confidence helped him secure a faculty position at mcgill in 2004. it was a good match: his research interests fit well at the institute, with its expertise in imaging techniques like mri and pet.   making the transition from a postdoc to a faculty position at mni, though, has required a bit of neural development, especially in the areas of his brain responsible for cognitive tasks like management and grant-writing \"as a faculty member, there are a lot of people that depend on me now.\" managing the lab, plus writing grant proposals and attending committee meetings, take up valuable research time. fortunately, mni deliberately limits the amount of teaching and committee work required of researchers setting up their labs, for which he is grateful. \"it's already hard enough to get going in a very competitive research funding environment.\"  ruthazer's experiences have helped to shape his management style; he is convinced that a well-managed neuroscience lab can be self-sufficient. he encourages his students to strive to be independent, and to learn what is necessary to carry out a well-controlled, well-designed experiment. he sees his role as professor as principally to keep things on track and help the students stay up to date with the latest trends.  in setting up shop in a predominately french-speaking province, ruthazer feels that he has, in a sense, come full circle. even though his current research is not connected with studying languages, per se, language acquisition remains a great influence. he is amazed at how adaptable the human brain is and how fast it can learn new things, including language. \"while i may not be studying it directly, it's still forming the way that i look at the scientific questions i tackle everyday.\"   for more information on ruthazer's work and the montreal neurological institute (mni), check out their  .      .  \n"
    }
   ],
   "source": [
    "# since this notebook uses the column heading content and I don't feel like changing every single one yet\n",
    "df[\"Content\"] = df[\"text\"]\n",
    "\n",
    "print(df.loc[128]['input'])\n",
    "print(df.loc[128]['Content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2## 1. Text cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Special character cleaning\n",
    "\n",
    "We can see the following special characters:\n",
    "\n",
    "* ``\\r``\n",
    "* ``\\n``\n",
    "* ``\\`` before possessive pronouns (`government's = government\\'s`)\n",
    "* ``\\`` before possessive pronouns 2 (`Yukos'` = `Yukos\\'`)\n",
    "* ``\"`` when quoting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "9\n"
    }
   ],
   "source": [
    "# \\r and \\n\n",
    "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\'s'\", \"\")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\'\", \"\")\n",
    "# because I still need quotation marks\n",
    "print(df.loc[1][\"Content_Parsed_1\"].count(\"\\\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Upcase/downcase\n",
    "\n",
    "I already did this when importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Punctuation signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation signs won't have any predicting power, so we'll just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I use my own function to remove quotations before removing these punctuation marks\n",
    "\n",
    "df[\"Content_Parsed_2\"] = cls.no_punctuation(df[\"Content_Parsed_1\"], quotes=True)\n",
    "df[\"Content_Parsed_3\"] = [cls.replace_quotes(text) for text in df[\"Content_Parsed_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3\n  by    dward ruthazer (pictured left) is a mapmaker of sorts, but the maps he makes are not of places in the world. ruthazer studies brain development, charting intricate neurocircuitries in the hope of advancing treatments for injuries of the central nervous system and therapies for developmental disorders. like the neural connections he maps, ruthazers path has twisted and turned from china to japan and across north america, as he has investigated the mechanisms that shape the wiring of the human brain. for this young neuroscientist, working overseas in different cultures and acquiring new personal and professional skills provided a sense of independence and confidence as a researcher, qualities that he tries to instill in the students and trainees working in his laboratory.    less than a year after finishing his second postdoc at cold spring harbor laboratory in new york, ruthazer is settling in as assistant professor at mcgill universitys montreal neurological institute (mni) in montreal, quebec. in his laboratory, ruthazer and his staff are asking fundamental questions about how the brains neurocircuitry—the network of connections between neurons—develops.  using digital imagery and gene-transfer methods, he and his team observe labeled neurons in living tadpoles. the animals are subjected to sensory stimuli as the team analyzes alterations in neuronal connectivity. in one project, they place tadpoles in chambers with flashing lights and examine the changes in connectivity in the retinal ganglion cells in response to these visual stimulations. the results in tadpoles, says ruthazer, are of more than academic interest. \" QUOTATION_REPLACEMENT \"   ruthazer believes that investigating animal neurocircuit development will eventually lead to a better understanding of diseases, including schizophrenia and autism, where abnormal neurological wiring is thought to occur early in life. the developing post-natal brain, ruthazer explains, forms and refines synaptic connections in response to a set of inputs from the environment, a process that becomes less robust with age. ruthazer hopes his research on rewiring may eventually bring hope to adults suffering from accidental brain injuries, and offer the possibility of early diagnosis and treatment of autism and schizophrenia. \" QUOTATION_REPLACEMENT \"    as an undergraduate at princeton university, ruthazer exercised his own developing brain to fulfill longstanding interests in the life sciences and languages, graduating with a major in biology and a certificate in east asian studies. during this period he began to wonder how the human brain interprets environmental stimuli. while learning french and chinese, he became fascinated how sensory experiences, like language acquisition, are processed neurologically. \" QUOTATION_REPLACEMENT \" explains ruthazer. \" QUOTATION_REPLACEMENT \"   in his senior year at princeton in 1988, he completed his first neuroscience project, on songbird auditory systems. it was then that ruthazer decided that graduate school was his next step. but before he could commit to his research career, he says, he felt like he needed to practice his language skills, so he packed his bags and traveled to the southern tip of manchuria, china, to teach english for a year at a university. it was, he says, an amazing learning experience; being immersed in a culture and language so different from his own provided many new environmental stimuli.  back in the u.s. a year later, ruthazer commenced his neuroscience training, studying the plasticity of neural systems for his ph.d. at university of california at san francisco. in 1996, after he had completed his doctorate, he had an opportunity to do a postdoc in japan--his wifes homeland--on a joint national science foundation/japan society for the promotion of science  .  \" QUOTATION_REPLACEMENT \" he explains. \" QUOTATION_REPLACEMENT \" under the supervision of nobuhiko yamamoto, he was able to observe the formation of synaptic connections using slices of functioning cortical tissues.    ruthazer feels that his 2-year postdoc in japan helped him become more independent. despite a lab environment that he calls \" QUOTATION_REPLACEMENT \" ruthazer found that he was unable to lean heavily on a culture that seemed foreign. \" QUOTATION_REPLACEMENT \" he may have found similar opportunities back in the united states, he observes, but going to japan also gave him the opportunity to learn state-of-the-art imaging techniques and to set up a valuable collaboration in a foreign country, while also developing a greater sense of independence.   ruthazer returned stateside in 1999 and took up a postdoc in holly clines lab at cold spring harbor. cline, ruthazer recalls, entrusted him with some special opportunities. he was able to pursue novel experimental approaches on his own initiative, for instance, and to give talks on her behalf at meetings she was unable to attend. these opportunities further developed his sense of independence and gave him a better grasp of the direction his field was going in. ruthazer recommends that other scientific trainees pursue similar opportunities. \" QUOTATION_REPLACEMENT \" he says.    ruthazers growing independence and confidence helped him secure a faculty position at mcgill in 2004. it was a good match: his research interests fit well at the institute, with its expertise in imaging techniques like mri and pet.   making the transition from a postdoc to a faculty position at mni, though, has required a bit of neural development, especially in the areas of his brain responsible for cognitive tasks like management and grant-writing \" QUOTATION_REPLACEMENT \" managing the lab, plus writing grant proposals and attending committee meetings, take up valuable research time. fortunately, mni deliberately limits the amount of teaching and committee work required of researchers setting up their labs, for which he is grateful. \" QUOTATION_REPLACEMENT \"  ruthazers experiences have helped to shape his management style; he is convinced that a well-managed neuroscience lab can be self-sufficient. he encourages his students to strive to be independent, and to learn what is necessary to carry out a well-controlled, well-designed experiment. he sees his role as professor as principally to keep things on track and help the students stay up to date with the latest trends.  in setting up shop in a predominately french-speaking province, ruthazer feels that he has, in a sense, come full circle. even though his current research is not connected with studying languages, per se, language acquisition remains a great influence. he is amazed at how adaptable the human brain is and how fast it can learn new things, including language. \" QUOTATION_REPLACEMENT \"   for more information on ruthazers work and the montreal neurological institute (mni), check out their  .   .  \n"
    }
   ],
   "source": [
    "print(df.loc[128]['input'])\n",
    "print(df.loc[128]['Content_Parsed_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\\\"()\")\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
    "\n",
    "for punct_sign_sp in list(\"-/\"):\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].replace(punct_sign_sp, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.iloc[135]['input'])\n",
    "# print(df.iloc[135]['Content_Parsed_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this we are messing up with some numbers, but it's no problem since we aren't expecting any predicting power from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Possessive pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also remove possessive pronoun terminations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Stemming and Lemmatization\n",
    "\n",
    "Since stemming can produce output words that don't exist, we'll only use a lemmatization process at this moment. Lemmatization takes into consideration the morphological analysis of the words and returns words that do exist, so it will be more useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "------------------------------------------------------------\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Clara\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\Clara\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to lemmatize, we have to iterate through every word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.iloc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2\n  by  in a recent essay publish at   career   a well-published scientist and adjunct lecturer at the university of florida in gainesville explain what she have learn in apply for   since earn her doctorate in 2004 kaplan draw the conclusion that emphasize her ability to garner federal research grant be likely to make her more successful in her search for a faculty position right or wrong kaplan’s essay—and her willingness to share her experience—is welcome and useful such first-person reflections be likely to be valuable to job seekers altogether the number of institutions of higher learn in the unite state approach 4000 include more than 3000 nonprofit institutions thats a much bigger pool of potential job than those offer at 200 or so research universities and she may well be right a strong publication record be certainly a key to get hire and anything you can do to convince an institution that you can attract outside fund be likely to increase your odds of win an offer for a tenure-track post but theres another huge facet of what professors do that kaplan mention only in pass teach since 2006 i have apply for 35 tenure-track faculty position work as a professor at two institutions—both primarily undergraduate institutions—and serve on numerous faculty search committees in the case ive be involve in teach be often the factor that cause job applicants to rise to the top of the stack  list 108 us universities in its research university/very high research activity category and another 99 in the research university/high research activity category at institutions like these—especially the first group—scholarship trump teach in tenure evaluations and usually in hire that doesnt mean they dont care about teach but if your sole focus be on work at one of these institutions keep publish in top journals and keep work hard to show that you can get fund best of luck but the foundation list an additional 1623 institutions that grant bachelor degrees not count institutions with a  QUOTATION_REPLACEMENT  on areas such as engineer music or health professions—including 52 medical school where doctor train be the main objective another 1920 institutions include 752 for-profit institutions offer only or mainly associate degrees altogether the number of institutions of higher learn in the unite state approach 4000 include more than 3000 nonprofit institutions thats a much bigger pool of potential job than those offer at 200 or so research universities and for most of those job another first-author   paper or a strong argument for your ability to attract r01 fund isnt the most important qualification even at research universities teach be value more than many applicants realize and consider this almost all the serious candidates for a faculty job at a research university will be emphasize research accomplishments yes for such job you do need excellent research credentials but if you want your application to stand out from the hundreds of others maybe it make sense to hone—and then sell—outstanding classroom skills theres a bias implicit in doctoral train arise from the fact that almost everyone earn their graduate degree and do at least one postdoc at a research university there graduate and postdoc advisers want you to focus on get paper out and get grant its what you learn how to do and its what youre expose to research-university faculty members also like the idea of move their protégés into similar job partly because they consider their work more valuable than other kinds of work and partly because its the only world they know yet search committees at the vast majority of colleges arent look for a bunch of science paper or an r01 from the national institute of health we be look for a partner to help us in our primary mission educate undergraduate students we’re mine your materials for evidence that you have make efforts to design and implement creative and dynamic approach to pedagogy and mentor we want to know that youre not just another member of the research-focused crowd for job like these the best way to stand out among hundreds of applicants be to show that you know what kind of job youre apply for and that its different from other kinds of job show us that you care about effective teach provide evidence that you have participate in it meaningfully and intend to continue do so demonstrate teach excellence be nearly as rare among applicants—perhaps rarer—than a real research grant from a government agency and at most institutions it matter more few applicants go beyond the typical teach statement to show real evidence of a passion for instruction and an ability to inspire students through her hard work kaplan have establish an outstanding record of research accomplishments have do so perhaps she should focus on develop her teach skills and credentials to be fair it do depend partly on her specific career ambition and she do briefly mention teach in her essay on a short list of question one might use to assess one’s record follow a round of multiple academic rejections she include  QUOTATION_REPLACEMENT  if you find yourself ask that question then—unless your search be limit to those few institutions where research be the overwhelm focus—the answer be probably  QUOTATION_REPLACEMENT  or maybe its not more experience you need maybe you just need to find a more effective way to communicate who you be and who you plan to become as a teacher accomplish that and there be a good chance we’ll be call you to learn more your essay should be about 800 word long and personal in tone please send us your submission as an editable text document attachment in an e-mail message address to   subject in person submission microsoft word format be prefer but openoffice format be acceptable please do not include photograph or other attachments with the original submission we will give each manuscript we receive careful consideration and contact you within 6 weeks if we decide to publish your essay most essay will be edit prior to publication if you do not hear from us in 6 weeks feel free to submit your work elsewhere  be the david burpee chair in plant genetics and research at bucknell university in lewisburg pennsylvania previous to that he be an associate professor at the state university of new york plattsburgh he be the host and co-producer of the youtube series   and a frequent blogger for  \n"
    }
   ],
   "source": [
    "print(df.iloc[148]['input'])\n",
    "print(df.iloc[148]['Content_Parsed_5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although lemmatization doesn't work perfectly in all cases (as can be seen in the example below), it can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Clara\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'list'>\n"
    }
   ],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))\n",
    "print(type(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[\"you're\",\n \"you've\",\n \"you'll\",\n \"you'd\",\n 'yours',\n \"she's\",\n 'it',\n \"it's\",\n 'its',\n 'itself']"
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[0:10]\n",
    "\n",
    "pronouns = [\"i\",\"im\", \"ive\", \"id\",\"my\", \"me\", \"myself\",\"we\",\"wed\",\"weve\",\"us\",\"our\", \"ours\",\"ourselves\",\"you\",\"youre\", \"youve\",\"youd\",\"your\", \"yourself\", \"yourselves\",\"he\",\"hes\",\"hed\",\"hell\",\"him\",\"his\", \"himself\",\"she\",\"shes\",\"shell\",\"shed\",\"her\",\"hers\",\"herself\",\"they\",\"them\",\"their\",\"theirs\",\"themself\",\"themselves\"]\n",
    "stop_words_wo_pronouns = [word for word in stop_words if word not in pronouns]\n",
    "stop_words_wo_pronouns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the stop words, we'll handle a regular expression only detecting whole words, as seen in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = \"me eating a meal\"\n",
    "# word = \"me\"\n",
    "\n",
    "# # The regular expression is:\n",
    "# regex = r\"\\b\" + word + r\"\\b\"  # we need to build it like that to work properly\n",
    "\n",
    "# re.sub(regex, \"StopWord\", example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop through all the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words_wo_pronouns:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some dobule/triple spaces between words because of the replacements. However, it's not a problem because we'll tokenize by the spaces later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we'll show an original news article and its modifications throughout the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now, any academic scientist working in national science foundation (nsf)-funded fields is well aware of the agency\\'s \"broader impacts\" (bi) review criterion. for years, applicants for nsf grants have been required to supplement their discussion of a project\\'s \"intellectual merit\" (im) with a separate discussion of bi in the project summary. last week, nsf\\'s division of chemical, bioengineering, environmental, and transport systems (cbet), part of its engineering directorate, issued   reminding applicants that starting in 2014 proposals must also include separate bi and im sections in the project description narrative and in the section describing the results of prior nsf support. \"if any of these requirements (or any other requirement from nsf 13-1 document) are not met,\\xa0the proposal will not pass the nsf compliance check and will be returned without review,\" writes the cbet staff.\\xa0\"we would like to avoid such unfortunate instances for our division.\" nsf\\'s grant proposal guide is  . instructions for preparing the proposal are in  . here is the language on the bi criterion from the grant proposal guide: broader impacts may be accomplished through the research itself, through the activities that are directly related to specific research projects, or through activities that are supported by, but are complementary to the project. nsf values the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes. such outcomes include, but are not limited to: full participation of women, persons with disabilities, and underrepresented minorities in science, technology, engineering, and mathematics (stem); improved stem education and educator development at any level; increased public scientific literacy and public engagement with science and technology; improved well-being of individuals in society; development of a diverse, globally competitive stem workforce; increased partnerships between academia, industry, and others; improved national security; increased economic competitiveness of the united states; and enhanced infrastructure for research and education. you can find more discussion of the bi criterion in      .  careers.'"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Special character cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now, any academic scientist working in national science foundation (nsf)-funded fields is well aware of the agencys \"broader impacts\" (bi) review criterion. for years, applicants for nsf grants have been required to supplement their discussion of a projects \"intellectual merit\" (im) with a separate discussion of bi in the project summary. last week, nsfs division of chemical, bioengineering, environmental, and transport systems (cbet), part of its engineering directorate, issued   reminding applicants that starting in 2014 proposals must also include separate bi and im sections in the project description narrative and in the section describing the results of prior nsf support. \"if any of these requirements (or any other requirement from nsf 13-1 document) are not met,\\xa0the proposal will not pass the nsf compliance check and will be returned without review,\" writes the cbet staff.\\xa0\"we would like to avoid such unfortunate instances for our division.\" nsfs grant proposal guide is  . instructions for preparing the proposal are in  . here is the language on the bi criterion from the grant proposal guide: broader impacts may be accomplished through the research itself, through the activities that are directly related to specific research projects, or through activities that are supported by, but are complementary to the project. nsf values the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes. such outcomes include, but are not limited to: full participation of women, persons with disabilities, and underrepresented minorities in science, technology, engineering, and mathematics (stem); improved stem education and educator development at any level; increased public scientific literacy and public engagement with science and technology; improved well-being of individuals in society; development of a diverse, globally competitive stem workforce; increased partnerships between academia, industry, and others; improved national security; increased economic competitiveness of the united states; and enhanced infrastructure for research and education. you can find more discussion of the bi criterion in   .  careers.'"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Upcase/downcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now, any academic scientist working in national science foundation (nsf)-funded fields is well aware of the agencys \"broader impacts\" (bi) review criterion. for years, applicants for nsf grants have been required to supplement their discussion of a projects \"intellectual merit\" (im) with a separate discussion of bi in the project summary. last week, nsfs division of chemical, bioengineering, environmental, and transport systems (cbet), part of its engineering directorate, issued   reminding applicants that starting in 2014 proposals must also include separate bi and im sections in the project description narrative and in the section describing the results of prior nsf support. \"if any of these requirements (or any other requirement from nsf 13-1 document) are not met,\\xa0the proposal will not pass the nsf compliance check and will be returned without review,\" writes the cbet staff.\\xa0\"we would like to avoid such unfortunate instances for our division.\" nsfs grant proposal guide is  . instructions for preparing the proposal are in  . here is the language on the bi criterion from the grant proposal guide: broader impacts may be accomplished through the research itself, through the activities that are directly related to specific research projects, or through activities that are supported by, but are complementary to the project. nsf values the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes. such outcomes include, but are not limited to: full participation of women, persons with disabilities, and underrepresented minorities in science, technology, engineering, and mathematics (stem); improved stem education and educator development at any level; increased public scientific literacy and public engagement with science and technology; improved well-being of individuals in society; development of a diverse, globally competitive stem workforce; increased partnerships between academia, industry, and others; improved national security; increased economic competitiveness of the united states; and enhanced infrastructure for research and education. you can find more discussion of the bi criterion in   .  careers.'"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Punctuation signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now any academic scientist working in national science foundation nsf-funded fields is well aware of the agencys  QUOTATION_REPLACEMENT  bi review criterion for years applicants for nsf grants have been required to supplement their discussion of a projects  QUOTATION_REPLACEMENT  im with a separate discussion of bi in the project summary last week nsfs division of chemical bioengineering environmental and transport systems cbet part of its engineering directorate issued   reminding applicants that starting in 2014 proposals must also include separate bi and im sections in the project description narrative and in the section describing the results of prior nsf support  QUOTATION_REPLACEMENT  writes the cbet staff\\xa0 QUOTATION_REPLACEMENT  nsfs grant proposal guide is   instructions for preparing the proposal are in   here is the language on the bi criterion from the grant proposal guide  QUOTATION_REPLACEMENT  may be accomplished through the research itself through the activities that are directly related to specific research projects or through activities that are supported by but are complementary to the project nsf values the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes such outcomes include but are not limited to full participation of women persons with disabilities and underrepresented minorities in science technology engineering and mathematics stem improved stem education and educator development at any level increased public scientific literacy and public engagement with science and technology improved well-being of individuals in society development of a diverse globally competitive stem workforce increased partnerships between academia industry and others improved national security increased economic competitiveness of the united states and enhanced infrastructure for research and education you can find more discussion of the bi criterion in     careers'"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Possessive pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now any academic scientist working in national science foundation nsf-funded fields is well aware of the agencys  QUOTATION_REPLACEMENT  bi review criterion for years applicants for nsf grants have been required to supplement their discussion of a projects  QUOTATION_REPLACEMENT  im with a separate discussion of bi in the project summary last week nsfs division of chemical bioengineering environmental and transport systems cbet part of its engineering directorate issued   reminding applicants that starting in 2014 proposals must also include separate bi and im sections in the project description narrative and in the section describing the results of prior nsf support  QUOTATION_REPLACEMENT  writes the cbet staff\\xa0 QUOTATION_REPLACEMENT  nsfs grant proposal guide is   instructions for preparing the proposal are in   here is the language on the bi criterion from the grant proposal guide  QUOTATION_REPLACEMENT  may be accomplished through the research itself through the activities that are directly related to specific research projects or through activities that are supported by but are complementary to the project nsf values the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes such outcomes include but are not limited to full participation of women persons with disabilities and underrepresented minorities in science technology engineering and mathematics stem improved stem education and educator development at any level increased public scientific literacy and public engagement with science and technology improved well-being of individuals in society development of a diverse globally competitive stem workforce increased partnerships between academia industry and others improved national security increased economic competitiveness of the united states and enhanced infrastructure for research and education you can find more discussion of the bi criterion in     careers'"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'  by  by now any academic scientist work in national science foundation nsf-funded field be well aware of the agencys  QUOTATION_REPLACEMENT  bi review criterion for years applicants for nsf grant have be require to supplement their discussion of a project  QUOTATION_REPLACEMENT  im with a separate discussion of bi in the project summary last week nsfs division of chemical bioengineering environmental and transport systems cbet part of its engineer directorate issue   remind applicants that start in 2014 proposals must also include separate bi and im section in the project description narrative and in the section describe the result of prior nsf support  QUOTATION_REPLACEMENT  write the cbet staff\\xa0 QUOTATION_REPLACEMENT  nsfs grant proposal guide be   instructions for prepare the proposal be in   here be the language on the bi criterion from the grant proposal guide  QUOTATION_REPLACEMENT  may be accomplish through the research itself through the activities that be directly relate to specific research project or through activities that be support by but be complementary to the project nsf value the advancement of scientific knowledge and activities that contribute to the achievement of societally relevant outcomes such outcomes include but be not limit to full participation of women persons with disabilities and underrepresented minorities in science technology engineer and mathematics stem improve stem education and educator development at any level increase public scientific literacy and public engagement with science and technology improve well-being of individuals in society development of a diverse globally competitive stem workforce increase partnerships between academia industry and others improve national security increase economic competitiveness of the unite state and enhance infrastructure for research and education you can find more discussion of the bi criterion in     career'"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'         decide  i want  move   lab  science communication see my   i   major route-planning   i usually travel fairly haphazardly  perhaps  change  career require less    QUOTATION_REPLACEMENT  attitude   first thing    completely revamp  date academic cv  -important list  publications  high-impact scientific journals suddenly seem less important  me  felt great  abandon  stifle format   academic research cv  attempt  reinvent myself within   punchy package    first hurdle   remove my list  publications  --high-impact journals  my ever-growing list  useful laboratory techniques i  face   rather sad realization  i  leave   little   way  skills  experience  document nevertheless  still felt good  dust   cobwebs    communication skills  i develop  my time  far   scientist  general scientists tend  acquire  develop communication skills     they need   my experience  appear   little room  research  devote  either personal  staff development    formal train environment i  already mention  write  phd thesis research manuscripts  several grant proposals   mean  i   science writer   description   although i  present my work  many meet  conferences  would  naive  unrealistic  me  consider myself   effective science communicator  nature   laboratory environment mean  i often    able  communicate effectively  team  disseminate my find  wider specialist  nonspecialist audiences   could i prove   potential employers   paper i  never leave  lab i find   daunt task  say  least  i decide  take two approach one  improve my general write skills     become  involve  issue    QUOTATION_REPLACEMENT    first step i set   meet   university information office  produce many newsletters  university staff members  students  well   wider audiences i could almost see  editors rub their hand  glee-- innocent fool volunteer     their hard graft  nothing   short notice they  ask me  produce several article  wide-ranging topics   them    scientific slant  i also find   valuable  cover subject i   prior knowledge   addition i find write book review  simple way  exercise my write skills  get something  press quickly  least  i  familiar   whole write edit  publish process  write word  longer seem like   mystery   i want    successful science writer  journalist   obviously  important  me  think   audiences i want  address   past i  always consider  public    huge unknown entity   i   far remove  time  come  familiarize myself   public  start  think   science mean  them   they  affect  scientific issue first i  start  pay  attention   science  report   media  light   genetically modify foods debate   actually  quite difficult  avoid analyze  scientific issue  dominate  public domain  addition i  get involve    public understand  science project    months ago i would  say   impossible  conduct  immunology lesson   class full  excitable 6-year-olds    challenge i take   get involve   local teacher-scientist network  aim   project   bring real-life science  scientists   classroom  enthuse children   wonder  science  generally  heighten their awareness  scientific issue  i  envisage talk  group  sixth formers   complexities   immune system  somewhere along  line i get partner   infant school i think  would  impossible  me  make  impact   6-year-olds understand  science    lot  imagination i  manage  invent many game   whole new language  explain  joy   immune system   impressionable audience  comparison organize science engineer  technology week events  gcse [high school diploma] students    walkover    i    stage  i   solid experience  proof  my skills   science communicator  include  my new smart cv   live   hope   my hard unpaid toil must soon pay '"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delete the intermediate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_x</th>\n      <th>first</th>\n      <th>second</th>\n      <th>wc</th>\n      <th>first_f</th>\n      <th>second_f</th>\n      <th>input</th>\n      <th>id_y</th>\n      <th>headline</th>\n      <th>tags</th>\n      <th>...</th>\n      <th>n_posts_author</th>\n      <th>column1</th>\n      <th>column2</th>\n      <th>Content</th>\n      <th>Content_Parsed_1</th>\n      <th>Content_Parsed_2</th>\n      <th>Content_Parsed_3</th>\n      <th>Content_Parsed_4</th>\n      <th>Content_Parsed_5</th>\n      <th>Content_Parsed_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>730</td>\n      <td>54</td>\n      <td>0</td>\n      <td>850</td>\n      <td>0.063529</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>6055</td>\n      <td>diary of a british scientist, part 2: brushing...</td>\n      <td>[job market, europe]</td>\n      <td>...</td>\n      <td>7</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by           so after deciding that i wanted...</td>\n      <td>by     so after deciding that i wanted to mo...</td>\n      <td>by     so after deciding that i wanted to mo...</td>\n      <td>by     so after deciding that i wanted to mo...</td>\n      <td>by     so after deciding that i wanted to mo...</td>\n      <td>by     so after decide that i want to move f...</td>\n      <td>decide  i want  move   lab  science c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 28 columns</p>\n</div>",
      "text/plain": "   id_x  first  second   wc   first_f  second_f  input  id_y  \\\n0   730     54       0  850  0.063529       0.0      1  6055   \n\n                                            headline                  tags  \\\n0  diary of a british scientist, part 2: brushing...  [job market, europe]   \n\n   ... n_posts_author column1 column2  \\\n0  ...              7      no     yes   \n\n                                             Content  \\\n0    by           so after deciding that i wanted...   \n\n                                    Content_Parsed_1  \\\n0    by     so after deciding that i wanted to mo...   \n\n                                    Content_Parsed_2  \\\n0    by     so after deciding that i wanted to mo...   \n\n                                    Content_Parsed_3  \\\n0    by     so after deciding that i wanted to mo...   \n\n                                    Content_Parsed_4  \\\n0    by     so after deciding that i wanted to mo...   \n\n                                    Content_Parsed_5  \\\n0    by     so after decide that i want to move f...   \n\n                                    Content_Parsed_6  \n0           decide  i want  move   lab  science c...  \n\n[1 rows x 28 columns]"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = [\"id_x\", \"input\", \"headline\", \"n_posts_author\",\"date_seq\",\"month_seq\",\"year\",\"column1\",\"column2\",\"text\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category_Code</th>\n      <th>headline</th>\n      <th>n_posts_author</th>\n      <th>date_seq</th>\n      <th>month_seq</th>\n      <th>year</th>\n      <th>column1</th>\n      <th>column2</th>\n      <th>text</th>\n      <th>Content_Parsed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>730</td>\n      <td>1</td>\n      <td>diary of a british scientist, part 2: brushing...</td>\n      <td>7</td>\n      <td>977</td>\n      <td>42</td>\n      <td>1999</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by           so after deciding that i wanted...</td>\n      <td>decide  i want  move   lab  science c...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4200</td>\n      <td>3</td>\n      <td>alyson reed takes the helm at npa</td>\n      <td>1</td>\n      <td>2545</td>\n      <td>93</td>\n      <td>2003</td>\n      <td>no</td>\n      <td>no</td>\n      <td>by     n 4 september, a new force joined the...</td>\n      <td>n 4 september  new force join  struggle   ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4453</td>\n      <td>1</td>\n      <td>unveiling the blindness</td>\n      <td>1</td>\n      <td>2699</td>\n      <td>98</td>\n      <td>2004</td>\n      <td>no</td>\n      <td>no</td>\n      <td>by      n a daily basis, i strive to be the ...</td>\n      <td>n  daily basis i strive    laziest mexica...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>286</td>\n      <td>2</td>\n      <td>talk yourself right into a job</td>\n      <td>247</td>\n      <td>7499</td>\n      <td>256</td>\n      <td>2017</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by  i’m sure you’ve heard the expression use...</td>\n      <td>i’ sure you’ hear  expression use  describ...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1034</td>\n      <td>3</td>\n      <td>loan-repayment for biomedical researchers</td>\n      <td>84</td>\n      <td>1901</td>\n      <td>72</td>\n      <td>2001</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by                            whatever happe...</td>\n      <td>whatever happen   fund proposal  cong...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     id  Category_Code                                           headline  \\\n0   730              1  diary of a british scientist, part 2: brushing...   \n1  4200              3                  alyson reed takes the helm at npa   \n2  4453              1                            unveiling the blindness   \n3   286              2                     talk yourself right into a job   \n4  1034              3          loan-repayment for biomedical researchers   \n\n   n_posts_author  date_seq  month_seq  year column1 column2  \\\n0               7       977         42  1999      no     yes   \n1               1      2545         93  2003      no      no   \n2               1      2699         98  2004      no      no   \n3             247      7499        256  2017      no     yes   \n4              84      1901         72  2001      no     yes   \n\n                                                text  \\\n0    by           so after deciding that i wanted...   \n1    by     n 4 september, a new force joined the...   \n2    by      n a daily basis, i strive to be the ...   \n3    by  i’m sure you’ve heard the expression use...   \n4    by                            whatever happe...   \n\n                                      Content_Parsed  \n0           decide  i want  move   lab  science c...  \n1      n 4 september  new force join  struggle   ...  \n2       n  daily basis i strive    laziest mexica...  \n3      i’ sure you’ hear  expression use  describ...  \n4           whatever happen   fund proposal  cong...  "
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed', 'id_x':'id','input':'Category_Code'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "We need to remember that our model will gather the latest news articles from different newspapers every time we want. For that reason, we not only need to take into account the peculiarities of the training set articles, but also possible ones that are present in the gathered news articles.\n",
    "\n",
    "For this reason, possible peculiarities have been studied in the *05. News Scraping* folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dictionary with the label codification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int32)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-580435652cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Category'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Category_Code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Category'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcategory_codes\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   4261\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4262\u001b[0m             \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4263\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4264\u001b[0m         )\n\u001b[0;32m   4265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   6680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6681\u001b[0m             return self.replace(\n\u001b[1;32m-> 6682\u001b[1;33m                 \u001b[0mto_replace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6683\u001b[0m             )\n\u001b[0;32m   6684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   4261\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4262\u001b[0m             \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4263\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4264\u001b[0m         )\n\u001b[0;32m   4265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   6700\u001b[0m                                 \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6701\u001b[0m                                 \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6702\u001b[1;33m                                 \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6703\u001b[0m                             )\n\u001b[0;32m   6704\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   4362\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4363\u001b[0m             \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4364\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4365\u001b[0m         )\n\u001b[0;32m   4366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   6734\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6735\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6736\u001b[1;33m                         \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6737\u001b[0m                     )\n\u001b[0;32m   6738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcomp\u001b[1;34m(s, regex)\u001b[0m\n\u001b[0;32m    608\u001b[0m                     \u001b[0mmaybe_convert_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masm8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 )\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[1;34m(a, b, regex)\u001b[0m\n\u001b[0;32m   1965\u001b[0m         raise TypeError(\n\u001b[0;32m   1966\u001b[0m             \"Cannot compare types {a!r} and {b!r}\".format(\n\u001b[1;32m-> 1967\u001b[1;33m                 \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m             )\n\u001b[0;32m   1969\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int32)' and 'str'"
     ]
    }
   ],
   "source": [
    "category_codes = {\n",
    "    'first':1,\n",
    "    'second':2,\n",
    "    'third':3\n",
    "}\n",
    "\n",
    "df['Category'] = df['Category_Code']\n",
    "df = df.replace({'Category':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Category mapping\n",
    "# df['Category_Code'] = df['Category']\n",
    "# df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category_Code</th>\n      <th>headline</th>\n      <th>n_posts_author</th>\n      <th>date_seq</th>\n      <th>month_seq</th>\n      <th>year</th>\n      <th>column1</th>\n      <th>column2</th>\n      <th>text</th>\n      <th>Content_Parsed</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>730</td>\n      <td>1</td>\n      <td>diary of a british scientist, part 2: brushing...</td>\n      <td>7</td>\n      <td>977</td>\n      <td>42</td>\n      <td>1999</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by           so after deciding that i wanted...</td>\n      <td>decide  i want  move   lab  science c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4200</td>\n      <td>3</td>\n      <td>alyson reed takes the helm at npa</td>\n      <td>1</td>\n      <td>2545</td>\n      <td>93</td>\n      <td>2003</td>\n      <td>no</td>\n      <td>no</td>\n      <td>by     n 4 september, a new force joined the...</td>\n      <td>n 4 september  new force join  struggle   ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4453</td>\n      <td>1</td>\n      <td>unveiling the blindness</td>\n      <td>1</td>\n      <td>2699</td>\n      <td>98</td>\n      <td>2004</td>\n      <td>no</td>\n      <td>no</td>\n      <td>by      n a daily basis, i strive to be the ...</td>\n      <td>n  daily basis i strive    laziest mexica...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>286</td>\n      <td>2</td>\n      <td>talk yourself right into a job</td>\n      <td>247</td>\n      <td>7499</td>\n      <td>256</td>\n      <td>2017</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by  i’m sure you’ve heard the expression use...</td>\n      <td>i’ sure you’ hear  expression use  describ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1034</td>\n      <td>3</td>\n      <td>loan-repayment for biomedical researchers</td>\n      <td>84</td>\n      <td>1901</td>\n      <td>72</td>\n      <td>2001</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>by                            whatever happe...</td>\n      <td>whatever happen   fund proposal  cong...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     id  Category_Code                                           headline  \\\n0   730              1  diary of a british scientist, part 2: brushing...   \n1  4200              3                  alyson reed takes the helm at npa   \n2  4453              1                            unveiling the blindness   \n3   286              2                     talk yourself right into a job   \n4  1034              3          loan-repayment for biomedical researchers   \n\n   n_posts_author  date_seq  month_seq  year column1 column2  \\\n0               7       977         42  1999      no     yes   \n1               1      2545         93  2003      no      no   \n2               1      2699         98  2004      no      no   \n3             247      7499        256  2017      no     yes   \n4              84      1901         72  2001      no     yes   \n\n                                                text  \\\n0    by           so after deciding that i wanted...   \n1    by     n 4 september, a new force joined the...   \n2    by      n a daily basis, i strive to be the ...   \n3    by  i’m sure you’ve heard the expression use...   \n4    by                            whatever happe...   \n\n                                      Content_Parsed  Category  \n0           decide  i want  move   lab  science c...         1  \n1      n 4 september  new force join  struggle   ...         3  \n2       n  daily basis i strive    laziest mexica...         1  \n3      i’ sure you’ hear  expression use  describ...         2  \n4           whatever happen   fund proposal  cong...         3  "
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'category':'Category_Code'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train - test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set apart a test set to prove the quality of our models. We'll do Cross Validation in the train set in order to tune the hyperparameters and then test performance on the unseen data of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train), len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have much observations (only 2.225), we'll choose a test set size of 15% of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have various options:\n",
    "\n",
    "* Count Vectors as features\n",
    "* TF-IDF Vectors as features\n",
    "* Word Embeddings as features\n",
    "* Text / NLP based features\n",
    "* Topic Models as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use **TF-IDF Vectors** as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define the different parameters:\n",
    "\n",
    "* `ngram_range`: We want to consider both unigrams and bigrams.\n",
    "* `max_df`: When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly higher than the given threshold\n",
    "* `min_df`: When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly lower than the given threshold.\n",
    "* `max_features`: If not None, build a vocabulary that only consider the top\n",
    "    max_features ordered by term frequency across the corpus.\n",
    "\n",
    "See `TfidfVectorizer?` for further detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument `norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen these values as a first approximation. Since the models that we develop later have a very good predictive power, we'll stick to these values. But it has to be mentioned that different combinations could be tried in order to improve even more the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(category_codes))\n",
    "\n",
    "category_codes.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have fitted and then transformed the training set, but we have **only transformed** the **test set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Chi squared test in order to see what unigrams and bigrams are most correlated with each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the unigrams correspond well to their category. However, bigrams do not. If we get the bigrams in our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are only six. This means the unigrams have more correlation with the category than the bigrams, and since we're restricting the number of features to the most representative 300, only a few bigrams are being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the files we'll need in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train\n",
    "with open('Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('Pickles/df.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}