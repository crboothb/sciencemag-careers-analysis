{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-bc335f077808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mabspath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "import os\n",
    "abspath = os.path.abspath(__file__)\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elist = \"../data/editorials-1.jl\"\n",
    "#tags = \"../data/by_article_110219.jl\"\n",
    "elist = \"D:/Box Sync/editorials/data/editorials-1.jl\"\n",
    "tags = \"D:/Box Sync/editorials/data/by_article_110219.jl\"\n",
    "\n",
    "def import_jl(filename):\n",
    "    filename = filename\n",
    "    full = open(filename, \"r\")\n",
    "    list = []\n",
    "    for x in full:\n",
    "        list.append(x)\n",
    "    return list\n",
    "\n",
    "editorial_raw = import_jl(elist)\n",
    "tags_raw = import_jl(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\"text\": \"\\nHefty university fees are sending some grad students to food banks\", \"preview\": \"\\n  \\nAs costs rise, students and faculty members are pushing back\\r\\n  \\n\", \"byline\": \"<p class=\\\"byline\\\">\\n  By <a href=\\\"/author/katie-langin\\\">Katie Langin</a><time>Aug. 12, 2019</time></p>\"}\n\n{\"headline\": \"A warning from the academic underground of adjuncts and contingent faculty\", \"tags\": [\"Read more Taken for Granted\", \"Taken for Granted\", \"Column\", \"Non-disciplinary\"], \"byline\": \"<p class=\\\"byline byline--article\\\">\\n  By <a href=\\\"/author/beryl-lieff-benderly\\\">Beryl Lieff Benderly</a><time>Jun. 10, 2019 , 2:30 PM</time></p>\"}\n\n"
    }
   ],
   "source": [
    "print(editorial_raw[5])\n",
    "print(tags_raw[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next 2 blocks for initially processing jl input files. the blocks are for editorials and tags respectively \n",
    "in the final version of this, I want to have them both in the same function\n",
    "an argument will indicate which file is being processeed. \n",
    "I want sidebar to be passed to the function, not inside it--as different scrapes could have different sidebars. However, to do this, I need to know how to make that argument optional, since sidebar will not be necessary for the tags file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(list, focus):\n",
    "    \n",
    "    list_temp1 = []\n",
    "    for line in list:\n",
    "        if \"null\" in line:\n",
    "            line = line.replace(\"null\", \"\\'null\\'\")\n",
    "        line = ast.literal_eval(line.lower())\n",
    "        list_temp1.append(line)\n",
    "    list = list_temp1\n",
    "\n",
    "    if focus == \"editorial\":\n",
    "        editorial_dict = {\"headline\":[], \"preview\":[],\"authors\":[],\"date\":[] }\n",
    "\n",
    "        sidebar = [\"how to keep a lab notebook\",\n",
    "                \"grad student unions dealt blow as proposed new rule says students aren’t ‘employees’\",\n",
    "                \"what do we know about ph.d. scientists’ career paths?\",\n",
    "                \"three lessons from industry that i’m taking back to academia\"\n",
    "                ]\n",
    "        for line in list:\n",
    "            if line[\"text\"].replace(\"\\n\",\"\")  in sidebar:\n",
    "                if line[\"preview\"] == \"null\":\n",
    "                    continue\n",
    "\n",
    "            editorial_dict[\"headline\"].append(line[\"text\"].replace(\"\\n\",\"\"))\n",
    "            editorial_dict[\"preview\"].append(line[\"preview\"].replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"  \",\"\"))\n",
    "            num_authors = (len(line[\"byline\"].replace(\"<\",\">\").split(\">\"))-5)//4\n",
    "            au = line[\"byline\"].replace(\"<\",\">\").split(\">\")[4]\n",
    "            for i in range(2,num_authors):\n",
    "                au += \", \" + line[\"byline\"].replace(\"<\",\">\").split(\">\")[i*4]\n",
    "            editorial_dict[\"authors\"].append(au)\n",
    "            editorial_dict[\"date\"].append(line[\"byline\"].replace(\"<\",\">\").split(\">\")[-5].replace(\". \",\"-\").replace(\", \",\"-\").replace(\" \",\"\").replace(\",\",\"\"))\n",
    "\n",
    "        editorial_df = pd.DataFrame(editorial_dict)\n",
    "        editorial_df[\"date\"] = pd.to_datetime(editorial_df.date, format='%b-%d-%Y')\n",
    "        editorial_df.sort_values(by=[\"date\"], inplace=True)\n",
    "        out_df = editorial_df\n",
    "        out_dict = editorial_dict\n",
    "    \n",
    "    elif focus == \"tags\":\n",
    "        tags_dict = {\"headline\":[],\"tags\":[],\"authors\":[],\"date\":[],\"time\":[] }\n",
    "\n",
    "\n",
    "        for line in list:\n",
    "        # if \"null\" in line:\n",
    "        #     line = line.replace(\"null\", \"\\'null\\'\")\n",
    "        #     line = ast.literal_eval(line)\n",
    "\n",
    "            head = line[\"headline\"].replace(\"\\n\",\"\").replace(\"\\\"\",\"\")\n",
    "            tags_dict[\"headline\"].append(head)\n",
    "\n",
    "            tags = line[\"tags\"]\n",
    "            unique_tags = []\n",
    "            for tag in tags:\n",
    "                if tag not in unique_tags:\n",
    "                    unique_tags.append(tag)\n",
    "            tags = unique_tags\n",
    "            if len(tags) < 1:\n",
    "                tags_dict[\"tags\"].append(\"[]\")\n",
    "            elif len(tags[0])< 5:\n",
    "                #tags_dict[\"tags\"].append(\", \".join(tags))\n",
    "                tags_dict[\"tags\"].append(tags)\n",
    "            elif tags[0][:5] == \"Read \":\n",
    "                if tags[0][10:-1] not in tags[1]:\n",
    "                    included = \"false\"\n",
    "                    for tag in tags[2:]:\n",
    "                        if tags[0][10:-1] in tag:\n",
    "                            #tags_dict[\"tags\"].append(\", \".join(tags[1:]))\n",
    "                            tags_dict[\"tags\"].append(tags)\n",
    "                            included = \"true\"\n",
    "                            break\n",
    "                    if included == \"false\":\n",
    "                        tags[0] = tags[0][10:]\n",
    "                        #tags_dict[\"tags\"].append(\", \".join(tags))\n",
    "                        tags_dict[\"tags\"].append(tags)\n",
    "\n",
    "                else:\n",
    "                    #tags_dict[\"tags\"].append(\", \".join(tags[1:]))\n",
    "                    tags_dict[\"tags\"].append(tags)\n",
    "            else:\n",
    "                #tags_dict[\"tags\"].append(\", \".join(tags))\n",
    "                tags_dict[\"tags\"].append(tags)\n",
    "\n",
    "            num_authors = (len(line[\"byline\"].replace(\"<\",\">\").split(\">\"))-5)//4\n",
    "            au = line[\"byline\"].replace(\"<\",\">\").split(\">\")[4]\n",
    "            for i in range(2,num_authors):\n",
    "                au += \", \" + line[\"byline\"].replace(\"<\",\">\").split(\">\")[i*4]\n",
    "            tags_dict[\"authors\"].append(au)\n",
    "\n",
    "            date_time = line[\"byline\"].replace(\"<\",\">\").split(\">\")[-5]\n",
    "            time = date_time[-7:]\n",
    "            date = date_time[:-9].replace(\". \",\"-\").replace(\", \",\"-\").replace(\" \",\"\").replace(\",\",\"\")\n",
    "            tags_dict[\"date\"].append(date)\n",
    "            tags_dict[\"time\"].append(time)\n",
    "\n",
    "\n",
    "        #print(tags_dict)\n",
    "\n",
    "        tags_df = pd.DataFrame(tags_dict)\n",
    "        tags_df.head()\n",
    "        tags_df[\"date\"] = pd.to_datetime(tags_df.date, format='%b-%d-%Y')\n",
    "        tags_df[\"date\"] = pd.to_datetime(tags_df[\"date\"])\n",
    "        tags_df.sort_values(by=[\"date\"], inplace=True)\n",
    "        out_df = tags_df\n",
    "        out_dict = tags_dict\n",
    "  \n",
    "    return [out_df, out_dict]\n",
    " \n",
    "out_edi = process(editorial_raw, \"editorial\")\n",
    "out_tag = process(tags_raw, \"tags\")\n",
    "\n",
    "edi_df = out_edi[0]\n",
    "edi_dict = out_edi[1]\n",
    "\n",
    "tag_df = out_tag[0]\n",
    "tag_dict = out_tag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "6312\n7324\n6136\n6136\n176\n###################################################\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline</th>\n      <th>tags</th>\n      <th>authors</th>\n      <th>date</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5969</td>\n      <td>how to write a winning résumé</td>\n      <td>[tooling up, advice, graduate, academic, industry, americas, united states]</td>\n      <td>peter fiske</td>\n      <td>1996-10-18</td>\n      <td>8:00 am</td>\n    </tr>\n    <tr>\n      <td>5968</td>\n      <td>the commandments of cover letter creation</td>\n      <td>[tooling up, advice, americas]</td>\n      <td>peter fiske</td>\n      <td>1996-12-20</td>\n      <td>0:00 am</td>\n    </tr>\n    <tr>\n      <td>5974</td>\n      <td>his mother cried when he went into sales</td>\n      <td>[tooling up, advice, graduate, postdoc, industry, biomedical, americas]</td>\n      <td>david g. jensen</td>\n      <td>1997-05-09</td>\n      <td>8:00 am</td>\n    </tr>\n    <tr>\n      <td>5973</td>\n      <td>what are headhunters and how do they work?</td>\n      <td>[tooling up, advice, graduate, midcareer, postdoc, industry, biomedical, americas]</td>\n      <td>david g. jensen</td>\n      <td>1997-09-12</td>\n      <td>8:00 am</td>\n    </tr>\n    <tr>\n      <td>5996</td>\n      <td>dressing scientists for success: male case study</td>\n      <td>[tooling up, advice, graduate, postdoc, academic, industry, americas]</td>\n      <td>peter fiske</td>\n      <td>1997-09-26</td>\n      <td>8:00 am</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              headline                                                                                tags  \\\n5969                     how to write a winning résumé         [tooling up, advice, graduate, academic, industry, americas, united states]   \n5968         the commandments of cover letter creation                                                      [tooling up, advice, americas]   \n5974          his mother cried when he went into sales             [tooling up, advice, graduate, postdoc, industry, biomedical, americas]   \n5973        what are headhunters and how do they work?  [tooling up, advice, graduate, midcareer, postdoc, industry, biomedical, americas]   \n5996  dressing scientists for success: male case study               [tooling up, advice, graduate, postdoc, academic, industry, americas]   \n\n              authors       date     time  \n5969      peter fiske 1996-10-18  8:00 am  \n5968      peter fiske 1996-12-20  0:00 am  \n5974  david g. jensen 1997-05-09  8:00 am  \n5973  david g. jensen 1997-09-12  8:00 am  \n5996      peter fiske 1997-09-26  8:00 am  "
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(edi_df))\n",
    "print(len(editorial_raw))\n",
    "print(len(tag_df))\n",
    "print(len(tags_raw))\n",
    "print(len(edi_df)-len(tag_df))\n",
    "\n",
    "print(\"###################################################\")\n",
    "\n",
    "# print(edi_df.head())\n",
    "# print(\"==================================================\")\n",
    "tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "6312\n6136\n176\n"
    }
   ],
   "source": [
    "# I wonder why they're different numbers\n",
    "print(len(edi_df))\n",
    "print(len(tag_df))\n",
    "print(len(edi_df)-len(tag_df))\n",
    "\n",
    "#print(edi_df[edi_df[\"headline\"] == \"Sowing the Seeds of Change\"])\n",
    "\n",
    "# Dammit, I wonder why...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes by headline column\n",
    "\n",
    "# still in progress needs a fuzzy join\n",
    "# merge_test = editorial.merge(tags, how = \"outer\", left_on = \"headline\", right_on = \"headline\", indicator = True)\n",
    "\n",
    "# print(len(merge_test))\n",
    "# print(len(merge_test[merge_test[\"_merge\"] != \"both\"]))\n",
    "# merge_test[merge_test[\"_merge\"] != \"both\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate means of processing sequential dates from the date of the first publication--basically, I hate the python dates function, and I'd rather use a function to go from sequential days to year instead of trying to extract the month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why am I doing this? I'm trying to calculate the months from the date_seq \n",
    "# Right now, this function returns a sequence from the actual start of the publications to the most recent publications\n",
    "# I would want later versions of this to be more flexible--maybe allowing the start and end times to be set in the function?\n",
    "\n",
    "def cumulative():\n",
    "    months_r = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    months_l = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "    # I need a list of cumulative days at the end of each month going forward\n",
    "    cumulative_days = [31, 61, 92]\n",
    "    cumulative_months = [13]\n",
    "\n",
    "    for year in range(1997,2021):\n",
    "        cumulative_months.append(cumulative_months[-1] + 12)\n",
    "        if year%4 == 0:\n",
    "            months = months_l\n",
    "        else:\n",
    "            months = months_r\n",
    "        for month in range(1,13):\n",
    "            #print(year, month)\n",
    "            #print(months[month-1])\n",
    "            cumulative_days.append(cumulative_days[-1]+months[month-1])\n",
    "    return(cumulative_days, cumulative_months)\n",
    "\n",
    "output = cumulative()\n",
    "\n",
    "# print(cumulative()[0])\n",
    "# print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}